{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "EE485 CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ms2UlM8JLuNb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FPd2XZIL8NW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "1eb565bd-3207-4432-d1fc-fe0442588397"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvrq-b6wMGgA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ccec4d30-d897-44a0-d367-19389875a691"
      },
      "source": [
        "cd drive/My\\ Drive/aircraft_data_64ptx/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/aircraft_data_64ptx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkRFWGW0LwJE",
        "colab_type": "text"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-M47pXG5LuNh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "681748a4-65a2-4ad9-e729-f312c5eee5fe"
      },
      "source": [
        "input_path = \"\" #\"D:\\\\Aircraft Dataset\\\\data\\\\64ptx\\\\\"\n",
        "drone_data = np.load(input_path + \"drone_image_data.npy\")\n",
        "fighter_data = np.load(input_path + \"fighter_image_data.npy\")\n",
        "helicopter_data = np.load(input_path + \"helicopter_image_data.npy\")\n",
        "missile_data = np.load(input_path + \"missile_image_data.npy\")\n",
        "plane_data = np.load(input_path + \"plane_image_data.npy\")\n",
        "rocket_data = np.load(input_path + \"rocket_image_data.npy\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9288df1ace43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minput_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m \u001b[0;31m#\"D:\\\\Aircraft Dataset\\\\data\\\\64ptx\\\\\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrone_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"drone_image_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfighter_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"fighter_image_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mhelicopter_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"helicopter_image_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmissile_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"missile_image_data.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drone_image_data.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexjXBDELuNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "e91242cd-732e-40b4-bd1c-81ed8ac364d5"
      },
      "source": [
        "data_without_label = np.concatenate((drone_data,fighter_data,helicopter_data, missile_data, plane_data, rocket_data), axis = 0).astype(np.float32)\n",
        "data_without_label /= 255.0\n",
        "print(\"Shape of the unlabeled data matrix: \" + str(data_without_label.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-43ae7c90a3ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_without_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrone_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfighter_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhelicopter_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissile_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplane_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrocket_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_without_label\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape of the unlabeled data matrix: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_without_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDMd7dpWLuNo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drone_data_flat = drone_data.reshape(drone_data.shape[0], -1).T\n",
        "fighter_data_flat = fighter_data.reshape(fighter_data.shape[0], -1).T\n",
        "helicopter_data_flat = helicopter_data.reshape(helicopter_data.shape[0], -1).T\n",
        "missile_data_flat = missile_data.reshape(missile_data.shape[0], -1).T\n",
        "plane_data_flat = plane_data.reshape(plane_data.shape[0], -1).T\n",
        "rocket_data_flat = rocket_data.reshape(rocket_data.shape[0], -1).T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1W0Ec-41LuNr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc107e11-c3d2-4121-880a-ecd53457e9d2"
      },
      "source": [
        "#one-hot encoding of the labels\n",
        "labels = np.array([1,0,0,0,0,0]).reshape(6,1)\n",
        "f_ix = 0\n",
        "l_ix = drone_data_flat.shape[1]\n",
        "for i in range(f_ix +1, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([1,0,0,0,0,0]).reshape(6,1)), axis = 1)\n",
        "f_ix += drone_data_flat.shape[1]\n",
        "l_ix += fighter_data_flat.shape[1]\n",
        "for i in range(f_ix, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([0,1,0,0,0,0]).reshape(6,1)), axis = 1)\n",
        "f_ix += fighter_data_flat.shape[1]\n",
        "l_ix += helicopter_data_flat.shape[1]\n",
        "for i in range(f_ix, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([0,0,1,0,0,0]).reshape(6,1)), axis = 1)\n",
        "f_ix += helicopter_data_flat.shape[1]\n",
        "l_ix += missile_data_flat.shape[1]\n",
        "for i in range(f_ix, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([0,0,0,1,0,0]).reshape(6,1)), axis = 1)\n",
        "f_ix += missile_data_flat.shape[1]\n",
        "l_ix += plane_data_flat.shape[1]\n",
        "for i in range(f_ix, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([0,0,0,0,1,0]).reshape(6,1)), axis = 1)\n",
        "f_ix += plane_data_flat.shape[1]\n",
        "l_ix += rocket_data_flat.shape[1]\n",
        "for i in range(f_ix, l_ix):\n",
        "    labels = np.concatenate((labels, np.array([0,0,0,0,0,1]).reshape(6,1)), axis = 1)\n",
        "labels = labels.T\n",
        "print(\"Shape of the one-hot encoded label matrix: \" + str(labels.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of the one-hot encoded label matrix: (8078, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOqckPV6LuNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#data = np.concatenate((data_without_label, labels.T), axis = 0)\n",
        "#print(\"Shape of the data matrix is:\" + str(data.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPshsaA7LuNy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "indexes = [i for i in range(labels.shape[0])]\n",
        "#shuufle the indexes\n",
        "np.random.shuffle(indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9DxbhbpLuN2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "8ec5f487-23eb-48e6-8c3e-db300226bbce"
      },
      "source": [
        "#divide the data into train and test along with the labels\n",
        "train_percentage = int(labels.shape[0]*0.7) #use the 90% of the data as training data\n",
        "train_data = data_without_label[indexes[0:train_percentage],:,:,:]\n",
        "train_label = labels[indexes[0:train_percentage],:]\n",
        "test_data = data_without_label[indexes[train_percentage:-1],:,:,:]\n",
        "test_label = labels[indexes[train_percentage:-1],:]\n",
        "\n",
        "print(\"shape of the training set and training label\" + str([train_data.shape, train_label.shape]))\n",
        "print(\"shape of the training set and training label\" + str([test_data.shape, test_label.shape]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of the training set and training label[(5654, 64, 64, 3), (5654, 6)]\n",
            "shape of the training set and training label[(2423, 64, 64, 3), (2423, 6)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkh-f7oILuN6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def zero_pad(X, pad):\n",
        "    return np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), mode = 'constant', constant_values = (0,0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9O-37NPLuN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_single_step(a_slice_prev, W, b):\n",
        "    # Applying one step of convolution to the sliced part of A with the filter W, and bias b.\n",
        "    s = a_slice_prev * W\n",
        "    Z = np.sum(s) + b\n",
        "    return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWQmuc_DLuOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_forward(A_prev, W, b, hparameters):\n",
        "    #Forward propagation for a convolution function in a single layer.\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "    \n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters[\"pad\"]\n",
        "    \n",
        "    n_H = int((n_H_prev + 2*pad - f)/2 + 1)\n",
        "    n_W = int((n_W_prev + 2*pad - f)/2 + 1)\n",
        "    \n",
        "    #initialize output matrix Z\n",
        "    Z = np.zeros((m, n_H, n_W, n_C))\n",
        "    \n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    \n",
        "    for i in range(m):               \n",
        "        a_prev_pad = A_prev_pad[i,:,:,:]\n",
        "        for h in range(n_H):\n",
        "            vert_start = h*stride\n",
        "            vert_end = vert_start + f\n",
        "            \n",
        "            for w in range(n_H):\n",
        "                horiz_start = w*stride\n",
        "                horiz_end = horiz_start + f\n",
        "                \n",
        "                for c in range(n_C):\n",
        "                    a_slice_prev = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end,:]\n",
        "                    #print(a_slice_prev.shape)\n",
        "                    # Convolving the slice with the filter W and bias b\n",
        "                    weights = W[:,:,:,c]\n",
        "                    #print(\"W: \" + str(weights.shape))\n",
        "                    biases = b[:,:,:,c]\n",
        "                    #print(\"b: \" + str(biases.shape))\n",
        "                    Z[i, h, w, c] = conv_single_step(a_slice_prev, weights, biases)\n",
        "                                        \n",
        "    assert(Z.shape == (m, n_H, n_W, n_C))\n",
        "    \n",
        "    # Saving information in \"cache\" for the backprop\n",
        "    cache = (A_prev, W, b, hparameters)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1HbiXiyLuOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
        "    #The forward pass of the pooling layer \n",
        "\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "\n",
        "    f = hparameters[\"f\"]\n",
        "    stride = hparameters[\"stride\"]\n",
        "\n",
        "    n_H = int(1 + (n_H_prev - f) / stride)\n",
        "    n_W = int(1 + (n_W_prev - f) / stride)\n",
        "    n_C = n_C_prev\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    A = np.zeros((m, n_H, n_W, n_C))              \n",
        "    \n",
        "    for i in range(m):                         \n",
        "        for h in range(n_H):\n",
        "            vert_start = h*stride\n",
        "            vert_end = vert_start + f\n",
        "            for w in range(n_W):\n",
        "                horiz_start = w*stride\n",
        "                horiz_end = horiz_start + f\n",
        "                for c in range (n_C):\n",
        "                    a_prev_slice = A_prev[i,vert_start:vert_end, horiz_start:horiz_end,:]\n",
        "                    if mode == \"max\":\n",
        "                        A[i, h, w, c] = np.max(a_prev_slice)\n",
        "                    elif mode == \"average\":\n",
        "                        A[i, h, w, c] = np.mean(a_prev_slice)\n",
        "                        \n",
        "    # Store the input and hparameters in \"cache\" for pool_backward()\n",
        "    cache = (A_prev, hparameters)\n",
        "\n",
        "    assert(A.shape == (m, n_H, n_W, n_C))\n",
        "\n",
        "    return A, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJMQ_cd4LuOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def conv_backward(dZ, cache):\n",
        "    #Back-propagation for a convolution function in a single layer\n",
        "    #retrieve info from cache\n",
        "    (A_prev, W, b, hparameters) = cache\n",
        "\n",
        "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
        "    #print(A_prev.shape)\n",
        "    (f, f, n_C_prev, n_C) = W.shape\n",
        "\n",
        "    stride = hparameters[\"stride\"]\n",
        "    pad = hparameters[\"pad\"]\n",
        "  \n",
        "    (m, n_H, n_W, n_C) = dZ.shape\n",
        "    \n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    \n",
        "    dW = np.zeros(W.shape)\n",
        "    db = np.zeros(b.shape)\n",
        "\n",
        "    A_prev_pad = zero_pad(A_prev, pad)\n",
        "    dA_prev_pad = zero_pad(dA_prev, pad)\n",
        "    \n",
        "    for i in range(m):\n",
        "        a_prev_pad = A_prev_pad[i]\n",
        "        da_prev_pad = dA_prev_pad[i]\n",
        "        \n",
        "        for h in range(n_H):    \n",
        "            for w in range(n_W):              \n",
        "                for c in range(n_C):          \n",
        "                    vert_start = h*stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w*stride\n",
        "                    horiz_end = horiz_start + f\n",
        "\n",
        "                    a_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
        "                    da_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :] += W[:,:,:,c] * dZ[i, h, w, c]\n",
        "                    dW[:,:,:,c] += a_slice * dZ[i, h, w, c]\n",
        "                    db[:,:,:,c] += dZ[i, h, w, c]\n",
        "            \n",
        "        if(pad == 0):\n",
        "            dA_prev[i, :, :, :] = da_prev_pad\n",
        "        else:\n",
        "            dA_prev[i, :, :, :] = da_prev_pad[pad:-pad, pad:-pad, :]\n",
        "\n",
        "    assert(dA_prev.shape == (m, n_H_prev, n_W_prev, n_C_prev))\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylyujDB-LuOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask_from_window(x):\n",
        "    return np.max(x) == x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9NcdqbzLuOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def distribute_value(dz, shape):\n",
        "    (n_H, n_W) = shape\n",
        "    average = dz/ (n_H*n_W)\n",
        "    a = np.ones(shape) * average\n",
        "    return a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_6FBvUJLuOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pool_backward(dA, cache, mode = \"max\"):\n",
        "    #back-propagation of the pooling layer\n",
        "\n",
        "    (A_prev, hparameters) = cache\n",
        "\n",
        "    stride = hparameters[\"stride\"]\n",
        "    f = hparameters[\"f\"]\n",
        "\n",
        "    m, n_H_prev, n_W_prev, n_C_prev = A_prev.shape\n",
        "    m, n_H, n_W, n_C = dA.shape\n",
        "    dA_prev = np.zeros(A_prev.shape)\n",
        "    \n",
        "    for i in range(m):\n",
        "        a_prev = A_prev[i]\n",
        "        for h in range(n_H):                 \n",
        "            for w in range(n_W):               \n",
        "                for c in range(n_C):\n",
        "                    vert_start = h*stride\n",
        "                    vert_end = vert_start + f\n",
        "                    horiz_start = w*stride\n",
        "                    horiz_end = horiz_start + f\n",
        "                    \n",
        "                    # Compute the back-propagation in both modes.\n",
        "                    if mode == \"max\":\n",
        "                        a_prev_slice = a_prev[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "                        mask = create_mask_from_window(a_prev_slice)\n",
        "                        #print(mask.shape)\n",
        "                        #print(dA[i,h,:,:].shape)\n",
        "                        #print(dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c].shape)\n",
        "                        #print([vert_start, vert_end, horiz_start, horiz_end])\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += np.multiply(mask,dA[i,h,w,c])\n",
        "                        \n",
        "                    elif mode == \"average\":\n",
        "                        da = dA[i,h,w,c]\n",
        "                        shape = (f,f)\n",
        "                        dA_prev[i, vert_start: vert_end, horiz_start: horiz_end, c] += distribute_value(da, shape)\n",
        "\n",
        "    assert(dA_prev.shape == A_prev.shape)\n",
        "    \n",
        "    return dA_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcUBngShLuOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters_FCLayers(layer_dims):\n",
        "    #initializing parameter for the fully connected layer\n",
        "    np.random.seed(3)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)            # number of layers in the network\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1])) * 0.01\n",
        "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
        "\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SymQRtJLuOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x): \n",
        "    return 1 / (1 + np.exp(x*-1)), x\n",
        "\n",
        "def relu(x):\n",
        "    return x * (x > 0), x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmUA4UjFLuOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_forward(A, W, b):\n",
        "    #calculation of the weights * input + bias for one layer\n",
        "    Z = np.matmul(W, A) + b\n",
        "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
        "    cache = (A, W, b)\n",
        "    \n",
        "    return Z, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "daAGUUZkLuOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_forward(A_prev, W, b, activation):\n",
        "    if activation == \"sigmoid\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = sigmoid(Z)\n",
        "    elif activation == \"relu\":\n",
        "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
        "        A, activation_cache = relu(Z)\n",
        "    \n",
        "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
        "    cache = (linear_cache, activation_cache)\n",
        "\n",
        "    return A, cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-f4h2bJ0LuOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_forward(X, parameters):\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2                  # number of layers in the neural network\n",
        "    \n",
        "    #Linear forward pass with ReLU for L-1 layers\n",
        "    for l in range(1, L):\n",
        "        A_prev = A \n",
        "        A, cache = linear_activation_forward(A_prev, parameters[\"W\" + str(l)], parameters[\"b\" + str(l)], \"relu\")\n",
        "        caches.append(cache)\n",
        "    \n",
        "    #Sigmoid activation for the last layer \n",
        "    AL, cache = linear_activation_forward(A, parameters[\"W\" + str(L)], parameters[\"b\" + str(L)], \"sigmoid\")\n",
        "    caches.append(cache)\n",
        "\n",
        "    #assert(AL.shape == (1,X.shape[1]))\n",
        "            \n",
        "    return AL, caches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izIvJQufLuOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(AL, Y):\n",
        "    #cross-entropy cost function\n",
        "    \n",
        "    m = AL.shape[0]\n",
        "    costs = []\n",
        "    #print(AL.shape, Y.shape)\n",
        "    for i in range(m):\n",
        "        costs.append( np.sum(Y.T[i]*np.log(AL[i]) + (1-Y.T[i])*np.log(1-AL[i]))*(-1/m) )\n",
        "\n",
        "    cost = np.squeeze(sum(costs))\n",
        "    assert(cost.shape == ())\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ym0Dca0LuOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid_backward(dA, cache):\n",
        "    Z = cache\n",
        "    s, _ = sigmoid(Z)\n",
        "    #print(dA.shape, s.shape)\n",
        "    #print(str(type(dA))+ \" \"+str(type(s)))\n",
        "    dZ = dA * s * (1-s)\n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ\n",
        "def relu_backward(dA, cache):\n",
        "    Z = cache\n",
        "    dZ = np.array(dA, copy=True)\n",
        "    dZ[Z <= 0] = 0\n",
        "\n",
        "    assert (dZ.shape == Z.shape)\n",
        "    \n",
        "    return dZ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdTNOBCjLuOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_backward(dZ, cache):\n",
        "    #back_propagation for linear portion of the layer\n",
        "    A_prev, W, b = cache\n",
        "    m = A_prev.shape[1]\n",
        "\n",
        "    dW = np.matmul(dZ, A_prev.T) /m\n",
        "    db = np.sum(dZ, axis = 1, keepdims = True) /m\n",
        "    dA_prev = np.matmul(W.T, dZ)\n",
        "    \n",
        "    assert (dA_prev.shape == A_prev.shape)\n",
        "    assert (dW.shape == W.shape)\n",
        "    assert (db.shape == b.shape)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEPgsqInLuOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def linear_activation_backward(dA, cache, activation):\n",
        "    #Back-propagation for the Linear activation\n",
        "    linear_cache, activation_cache = cache\n",
        "    if activation == \"relu\":\n",
        "        dZ = relu_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    elif activation == \"sigmoid\":\n",
        "        dZ = sigmoid_backward(dA, activation_cache)\n",
        "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
        "    \n",
        "    return dA_prev, dW, db"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIF2_bLzLuOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def L_model_backward(AL, Y, caches):\n",
        "    grads = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) \n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "   \n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "    \n",
        "    # Loop from l=L-2 to l=0 for relu\n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "        \n",
        "    return grads\n",
        "\n",
        "def L_model_backward_adam(AL, Y, caches):\n",
        "    grads = {}\n",
        "    #adam_parameters = {}\n",
        "    L = len(caches) # the number of layers\n",
        "    m = AL.shape[1]\n",
        "    Y = Y.reshape(AL.shape) \n",
        "    \n",
        "    # Initializing the backpropagation\n",
        "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
        "   \n",
        "    current_cache = caches[L-1]\n",
        "    grads[\"dA\" + str(L-1)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, \"sigmoid\")\n",
        "    #adam_parameters[\"vdW\" + str(L)], adam_parameters[\"vdb\" + str(L)], adam_parameters[\"sdW\" + str(L)], adam_parameters[\"sdb\" + str(L)] = 0,0,0,0\n",
        "    # Loop from l=L-2 to l=0 for relu\n",
        "    for l in reversed(range(L-1)):\n",
        "        current_cache = caches[l]\n",
        "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l+1)], current_cache, \"relu\")\n",
        "        grads[\"dA\" + str(l)] = dA_prev_temp\n",
        "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
        "        grads[\"db\" + str(l + 1)] = db_temp\n",
        "        #adam_parameters[\"vdW\" + str(l+1)], adam_parameters[\"vdb\" + str(l+1)], adam_parameters[\"sdW\" + str(l+1)], adam_parameters[\"sdb\" + str(l+1)] = 0,0,0,0\n",
        "    return grads#, adam_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yvsPSw3LuOz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(L):\n",
        "        parameters[\"W\" + str(l+1)] -= learning_rate * grads[\"dW\" + str(l+1)]\n",
        "        parameters[\"b\" + str(l+1)] -= learning_rate * grads[\"db\" + str(l+1)]\n",
        "        \n",
        "    return parameters\n",
        "\n",
        "def update_parameters_adam(parameters, grads, adam_parameters, learning_rate, iteration, beta1 = 0.9, beta2 = 0.999, epsilon = 1e-8):\n",
        "    L = len(parameters) // 2\n",
        "    #print(grads[\"dW\" + str(1)])\n",
        "    for l in range(L):\n",
        "        adam_parameters[\"vdW\" + str(l+1)] = beta1 * adam_parameters[\"vdW\" + str(l+1)] + (1-beta1)*grads[\"dW\" + str(l+1)]\n",
        "        adam_parameters[\"vdb\" + str(l+1)] = beta1 * adam_parameters[\"vdb\" + str(l+1)] + (1-beta1)*grads[\"db\" + str(l+1)]\n",
        "        adam_parameters[\"sdW\" + str(l+1)] = beta2 * adam_parameters[\"sdW\" + str(l+1)] + (1-beta2)*(grads[\"dW\" + str(l+1)]**2)\n",
        "        adam_parameters[\"sdb\" + str(l+1)] = beta2 * adam_parameters[\"sdb\" + str(l+1)] + (1-beta2)*(grads[\"db\" + str(l+1)]**2)\n",
        "        #print(\"vdw, vdb, sdw, sdb: \" + str(vdW)+str(vdb)+str(sdW)+str(sdb))\n",
        "        vdWcor = adam_parameters[\"vdW\" + str(l+1)] / (1 - (beta1**(iteration)))\n",
        "        vdbcor = adam_parameters[\"vdb\" + str(l+1)] / (1 - (beta1**(iteration)))\n",
        "        sdWcor = adam_parameters[\"sdW\" + str(l+1)] / (1 - (beta2**(iteration)))\n",
        "        sdbcor = adam_parameters[\"sdb\" + str(l+1)] / (1 - (beta2**(iteration)))\n",
        "\n",
        "        parameters[\"W\" + str(l+1)] -= learning_rate * vdWcor / ((sdWcor)**(0.5) + epsilon)\n",
        "        parameters[\"b\" + str(l+1)] -= learning_rate * vdbcor / ((sdbcor)**(0.5) + epsilon)\n",
        "        \n",
        "    return parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2jG0m7ULuO1",
        "colab_type": "text"
      },
      "source": [
        "# Overview of our CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUD_o0FcQyv9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initializeAdamParameters(L):\n",
        "    adam_parameters = {}\n",
        "    for layer in range(1,L+1):\n",
        "        adam_parameters[\"vdW\" + str(layer)], adam_parameters[\"vdb\" + str(layer)], adam_parameters[\"sdW\" + str(layer)], adam_parameters[\"sdb\" + str(layer)] = 0,0,0,0\n",
        "    return adam_parameters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVgzFRXLuO2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def CNNModel(X, Y, layers_dims, Wc1, bc1, Wc2, bc2, hparameters1, hparameters2, batch_size = 64, learning_rate = 0.0075, num_iterations = 3000, print_cost = True, useAdam = True):\n",
        "    \n",
        "    #number of fully connected layers\n",
        "    L = len(layers_dims)\n",
        "    costs = []\n",
        "    fcl_parameters = initialize_parameters_FCLayers(layers_dims)\n",
        "    adam_parameters = initializeAdamParameters(L) \n",
        "    \"\"\"\n",
        "    hparameters1 = {\"stride\": 1, \"f\": 3, \"pad\": 1}\n",
        "    hparameters2 = {\"stride\": 2, \"f\": 5, \"pad\": 0}\n",
        "    \"\"\"\n",
        "    print(X.shape)\n",
        "    #pick a random mini-batch from the dataset\n",
        "    #tmp_index = [i for i in range(X.shape[0])]\n",
        "    #np.random.shuffle(tmp_index)\n",
        "    #train_batch = X[tmp_index[0:batch_size], :,:,:]\n",
        "    #label_batch = Y[tmp_index[0:batch_size],:]\n",
        "    # Loop (gradient descent)\n",
        "    vdWc1, sdWc1, vdbc1, sdbc1 = 0, 0, 0, 0\n",
        "    vdWc2, sdWc2, vdbc2, sdbc2 = 0, 0, 0, 0\n",
        "    vdW, sdW, vdb, sdb = 0, 0, 0, 0\n",
        "    for i in range(0, num_iterations):\n",
        "        \"\"\"\n",
        "        for j in range(0, X.shape[0], batch_size): \n",
        "            # Forward propagation: Conv1 -> MaxPool -> Conv2 -> MaxPool \n",
        "            # -> [Linear with ReLU activation]*(L-1) -> Linear with Sigmoid activation.\n",
        "            \n",
        "            train_batch = X[j:j+batch_size, :,:,:]\n",
        "            label_batch = Y[j:j+batch_size, :]\n",
        "            \"\"\"\n",
        "        tmp_index = [i for i in range(X.shape[0])]\n",
        "        np.random.shuffle(tmp_index)\n",
        "        train_batch = X[tmp_index[0:batch_size], :,:,:]\n",
        "        label_batch = Y[tmp_index[0:batch_size],:]\n",
        "        out_conv1, cache1 = conv_forward(train_batch, Wc1, bc1, hparameters1)  #TODO RELU\n",
        "        print(\"out_conv1.shape\", out_conv1.shape)\n",
        "        out_conv1, relu1 = relu(out_conv1)\n",
        "        out_pool1, cache2 = pool_forward(out_conv1, hparameters1, mode = \"max\")\n",
        "        print(\"out_pool1.shape\", out_pool.shape)\n",
        "        out_conv2, cache3 = conv_forward(out_pool1, Wc2, bc2, hparameters2)  #TODO RELU\n",
        "        print(\"out_conv2.shape\", out_conv2.shape)\n",
        "        out_conv2, relu2 = relu(out_conv2)\n",
        "        out_pool2, cache4 = pool_forward(out_conv2, hparameters2, mode = \"max\")\n",
        "        print(\"out_pool2.shape\", out_pool2.shape)\n",
        "        input_forFCL = out_pool2.reshape(out_pool2.shape[0], -1).T\n",
        "        AL, caches = L_model_forward(input_forFCL, fcl_parameters)\n",
        "\n",
        "        # Compute cost.\n",
        "        cost = compute_cost(AL, label_batch)\n",
        "\n",
        "        \n",
        "\n",
        "        # Update parameters of the FCL\n",
        "        if(useAdam == False):\n",
        "            # Backward propagation.\n",
        "            grads = L_model_backward(AL, label_batch, caches)\n",
        "            fcl_parameters = update_parameters(fcl_parameters, grads, learning_rate)\n",
        "        else:\n",
        "            grads = L_model_backward_adam(AL, label_batch, caches)\n",
        "            #print(type(adam_parameters))\n",
        "            fcl_parameters = update_parameters_adam(fcl_parameters, grads, adam_parameters, learning_rate, (i+1), beta1=0.9, beta2=0.999)\n",
        "        \n",
        "        dInput_forFCL = grads[\"dA0\"].reshape(out_pool2.shape)\n",
        "        dPool2 = pool_backward(dInput_forFCL, cache4, mode = \"max\")\n",
        "        dPool2 = relu_backward(dPool2, relu2)  #TODO RELU\n",
        "        dConv2, dWc2, dbc2 = conv_backward(dPool2, cache3)\n",
        "        dPool1 = pool_backward(dConv2, cache2, mode = \"max\")\n",
        "        dPool1 = relu_backward(dPool1, relu1) #TODO RELU\n",
        "        dConv1, dWc1, dbc1 = conv_backward(dPool1, cache1)\n",
        "\n",
        "        #update the convolution parameters\n",
        "        if( useAdam == False):\n",
        "            Wc1 -= learning_rate * dWc1\n",
        "            bc1 -= learning_rate * dbc1\n",
        "            Wc2 -= learning_rate * dWc2\n",
        "            bc2 -= learning_rate * dbc2\n",
        "        else:\n",
        "            beta1, beta2, epsilon = 0.9, 0.999, 1e-8\n",
        "            vdWc1 = beta1 * vdWc1 + (1-beta1)*dWc1\n",
        "            vdbc1 = beta1 * vdbc1 + (1-beta1)*dbc1\n",
        "            sdWc1 = beta2 * sdWc1 + (1-beta2)*(dWc1**2)\n",
        "            sdbc1 = beta2 * sdbc1 + (1-beta2)*(dbc1**2)\n",
        "\n",
        "            vdWc2 = beta1 * vdWc2 + (1-beta1)*dWc2\n",
        "            vdbc2 = beta1 * vdbc2 + (1-beta1)*dbc2\n",
        "            sdWc2 = beta2 * sdWc2 + (1-beta2)*(dWc2**2)\n",
        "            sdbc2 = beta2 * sdbc2 + (1-beta2)*(dbc2**2)\n",
        "            #print(\"vdw, vdb, sdw, sdb: \" + str(vdW)+str(vdb)+str(sdW)+str(sdb))\n",
        "            vdWc1cor = vdWc1 / (1 - (beta1**(i+1)))\n",
        "            vdbc1cor = vdbc1 / (1 - (beta1**(i+1)))\n",
        "            sdWc1cor = sdWc1 / (1 - (beta2**(i+1)))\n",
        "            sdbc1cor = sdbc1 / (1 - (beta2**(i+1)))\n",
        "\n",
        "            vdWc2cor = vdWc2 / (1 - (beta1**(i+1)))\n",
        "            vdbc2cor = vdbc2 / (1 - (beta1**(i+1)))\n",
        "            sdWc2cor = sdWc2 / (1 - (beta2**(i+1)))\n",
        "            sdbc2cor = sdbc2 / (1 - (beta2**(i+1)))\n",
        "            #print(\"vdwcor, vdb, sdw, sdb: \" + str(vdWcor)+str(vdbcor)+str(sdWcor)+str(sdbcor))\n",
        "            #update the values with gradients and learning rate\n",
        "            #print(\"W,b bef:\" + str(W)+str(b))\n",
        "            Wc1 = Wc1 - learning_rate * vdWc1cor / ((sdWc1cor)**(0.5) + epsilon)\n",
        "            bc1 = bc1 - learning_rate * vdbc1cor / ((sdbc1cor)**(0.5) + epsilon)\n",
        "\n",
        "            Wc2 = Wc2 - learning_rate * vdWc2cor / ((sdWc2cor)**(0.5) + epsilon)\n",
        "            bc2 = bc2 - learning_rate * vdbc2cor / ((sdbc2cor)**(0.5) + epsilon)\n",
        "\n",
        "            \n",
        "        # Print the cost every 100 training example\n",
        "        if print_cost and i % 10 == 0:\n",
        "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
        "        if print_cost and i % 10 == 0:\n",
        "            costs.append(cost)\n",
        "            \n",
        "    # plot the cost\n",
        "    plt.plot(np.squeeze(costs))\n",
        "    plt.ylabel('cost')\n",
        "    plt.xlabel('iterations (per hundreds)')\n",
        "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "    plt.show()\n",
        "    \n",
        "    return Wc1, bc1, Wc2, bc2, fcl_parameters\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zgpTCCFiLuO4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predictCNN(X, Y, Wc1, bc1, Wc2, bc2, hparameters1, hparameters2, fcl_parameters):\n",
        "    \n",
        "    out_conv1, cache1 = conv_forward(X, Wc1, bc1, hparameters1)\n",
        "    out_conv1, relu1 = relu(out_conv1)\n",
        "    out_pool1, cache2 = pool_forward(out_conv1, hparameters1, mode = \"max\")\n",
        "        \n",
        "    out_conv2, cache3 = conv_forward(out_pool1, Wc2, bc2, hparameters2)\n",
        "    out_conv2, relu2 = relu(out_conv2)\n",
        "    out_pool2, cache4 = pool_forward(out_conv2, hparameters2, mode = \"max\")\n",
        "    input_forFCL = out_pool2.reshape(out_pool2.shape[0], -1).T\n",
        "    AL, caches = L_model_forward(input_forFCL, fcl_parameters)\n",
        "    m = AL.shape[1]\n",
        "    true_pred = 0\n",
        "    preds = []\n",
        "    for i in range(AL.shape[1]):\n",
        "        pred_ix = np.argmax(AL.T[i])\n",
        "        if(labels[i][pred_ix] == 1):\n",
        "            true_pred += 1\n",
        "        preds.append(pred_ix)\n",
        "    return true_pred / m, preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PxaU1QVhb8l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hparameters1 = {\"stride\": 1, \"f\": 3, \"pad\": 1}\n",
        "hparameters2 = {\"stride\": 2, \"f\": 5, \"pad\": 0}\n",
        "#initializing parameters for the first convolution filter (f = 3, # of filters = 10)\n",
        "Wc1 = np.random.randn(hparameters1[\"f\"], hparameters1[\"f\"], train_data.shape[3],10)\n",
        "bc1 = np.zeros((1,1,1,10))\n",
        "#initializing parameters for the second convolution filter (f = 5, # of filters = 10)\n",
        "Wc2 = np.random.randn(hparameters2[\"f\"], hparameters2[\"f\"], Wc1.shape[3],10)\n",
        "bc2 = np.zeros((1,1,1,10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMcZ_ktPLuO7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f4910491-af33-416c-f480-2d7a0f143897"
      },
      "source": [
        "layers_dims = [250, 32, 16, 6]\n",
        "Wc1f, bc1f, Wc2f, bc2f, fcl_parameters = CNNModel(train_data, train_label, layers_dims, Wc1f, bc1f, Wc2f, bc2f, hparameters1, hparameters2, batch_size =  32, learning_rate = 0.0005, num_iterations = 1, print_cost = True, useAdam = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-a672f45a48af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlayers_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mWc1f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc1f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWc2f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc2f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcl_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNNModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWc1f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc1f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWc2f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbc2f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparameters2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0005\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museAdam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMaqh9pPLuO9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d51fae83-22f9-4a81-aff1-caf5495dc51f"
      },
      "source": [
        "accuracy_tr, predictions_tr = predictCNN(train_data, train_label, Wc1f, bc1f, Wc2f, bc2f, hparameters1, hparameters2, fcl_parameters)\n",
        "print(\"accuracy on training set: \" + str(accuracy_tr))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on training set: 0.22974885037141846\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBfBYWMDLuO_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8bc0c58-d6fd-49d7-adde-56786447a634"
      },
      "source": [
        "accuracy_test, predictions_test = predictCNN(test_data, test_label, Wc1f, bc1f, Wc2f, bc2f, hparameters1, hparameters2, fcl_parameters)\n",
        "print(\"accuracy on test set: \" + str(accuracy_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy on test set: 0.5361122575319851\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9NQW891UDoG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(input_path + \"22-53acc_Wc1\", Wc1f)\n",
        "np.save(input_path + \"22-53acc_bc1\", bc1f)\n",
        "np.save(input_path + \"22-53acc_Wc2\", Wc2f)\n",
        "np.save(input_path + \"22-53acc_bc2\", bc2f)\n",
        "np.save(input_path + \"22-53fcl\", fcl_parameters)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}